{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** Multivariate Multi-Step Time Series Forecasting Models for Air Pollution\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The **Air Quality Prediction** dataset describes weather conditions at multiple sites.\n",
    "- The goal is to predict the air quality measurements over the subsequent three days.\n",
    "- This is a multi-step univariate time series analysis, because we have only one value recorder per time step but this depends on many inputs.\n",
    "- A **naive forecasts model** is develop which can be used as a baseline model. This is generally done to establish if the model is approprioate for this problem or note.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from numpy import nan\n",
    "from numpy import array\n",
    "from numpy import savetxt\n",
    "from pandas import read_csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The Air Quality Prediction dataset describes weather conditions at multiple sites and requires a prediction of air quality measurements over the subsequent three days.\n",
    "\n",
    "- Specifically, weather observations such as temperature, pressure, wind speed, and wind direction are provided hourly for eight days for multiple sites. The objective is to predict air quality measurements for the next 3 days at multiple sites. The forecast lead times are not contiguous; instead, specific lead times must be forecast over the 72 hour forecast period. They are:\n",
    "`+1, +2, +3, +4, +5, +10, +17, +24, +48, +72`\n",
    "\n",
    "- Further, the dataset is divided into disjoint but contiguous chunks of data, with eight days of data followed by three days that require a forecast.\n",
    "\n",
    "- Not all observations are available at all sites or chunks and not all output variables are available at all sites and chunks. There are large portions of missing data that must be addressed.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('../DATASETS/air_quality_dataset/TrainingData.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowID</th>\n",
       "      <th>chunkID</th>\n",
       "      <th>position_within_chunk</th>\n",
       "      <th>month_most_common</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>Solar.radiation_64</th>\n",
       "      <th>WindDirection..Resultant_1</th>\n",
       "      <th>WindDirection..Resultant_1018</th>\n",
       "      <th>WindSpeed..Resultant_1</th>\n",
       "      <th>...</th>\n",
       "      <th>target_4_6006</th>\n",
       "      <th>target_4_8003</th>\n",
       "      <th>target_5_6006</th>\n",
       "      <th>target_7_57</th>\n",
       "      <th>target_8_57</th>\n",
       "      <th>target_8_4002</th>\n",
       "      <th>target_8_6004</th>\n",
       "      <th>target_8_8003</th>\n",
       "      <th>target_9_4002</th>\n",
       "      <th>target_9_8003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>117.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.748424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.130631</td>\n",
       "      <td>1.341606</td>\n",
       "      <td>2.138792</td>\n",
       "      <td>3.013752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.679280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>231.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.144120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.130631</td>\n",
       "      <td>1.195779</td>\n",
       "      <td>2.722099</td>\n",
       "      <td>3.888712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.426751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>247.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.932469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.136395</td>\n",
       "      <td>1.409658</td>\n",
       "      <td>3.110970</td>\n",
       "      <td>3.888712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.683732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>219.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.088907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.217102</td>\n",
       "      <td>1.477711</td>\n",
       "      <td>2.041574</td>\n",
       "      <td>3.208188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.831243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.217102</td>\n",
       "      <td>1.458267</td>\n",
       "      <td>2.138792</td>\n",
       "      <td>3.499841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.625658</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.687052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.170984</td>\n",
       "      <td>1.604094</td>\n",
       "      <td>2.236010</td>\n",
       "      <td>3.305406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.833469</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>330.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.677850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.951554</td>\n",
       "      <td>1.555485</td>\n",
       "      <td>1.652703</td>\n",
       "      <td>2.430445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.854715</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>316.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.549019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.951554</td>\n",
       "      <td>1.711033</td>\n",
       "      <td>1.458267</td>\n",
       "      <td>1.361049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.595508</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>285.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.226941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.928495</td>\n",
       "      <td>1.623537</td>\n",
       "      <td>1.361049</td>\n",
       "      <td>1.263832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.621206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>337.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.815897</td>\n",
       "      <td>1.380493</td>\n",
       "      <td>1.263832</td>\n",
       "      <td>1.166614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.004452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 95 columns</p>\n",
""      ],
      "text/plain": [
       "   rowID  chunkID  position_within_chunk  month_most_common   weekday  hour  \\\n",
       "0      1        1                      1                 10  Saturday    21   \n",
       "1      2        1                      2                 10  Saturday    22   \n",
       "2      3        1                      3                 10  Saturday    23   \n",
       "3      4        1                      4                 10    Sunday     0   \n",
       "4      5        1                      5                 10    Sunday     1   \n",
       "5      6        1                      6                 10    Sunday     2   \n",
       "6      7        1                      7                 10    Sunday     3   \n",
       "7      8        1                      8                 10    Sunday     4   \n",
       "8      9        1                      9                 10    Sunday     5   \n",
       "9     10        1                     10                 10    Sunday     6   \n",
       "\n",
       "   Solar.radiation_64  WindDirection..Resultant_1  \\\n",
       "0                0.01                       117.0   \n",
       "1                0.01                       231.0   \n",
       "2                0.01                       247.0   \n",
       "3                0.01                       219.0   \n",
       "4                0.01                         2.0   \n",
       "5                0.01                       288.0   \n",
       "6                0.01                       330.0   \n",
       "7                0.01                       316.0   \n",
       "8                0.01                       285.0   \n",
       "9                0.05                       337.0   \n",
       "\n",
       "   WindDirection..Resultant_1018  WindSpeed..Resultant_1  ...  target_4_6006  \\\n",
       "0                          187.0                     0.3  ...       1.748424   \n",
       "1                          202.0                     0.5  ...       2.144120   \n",
       "2                          227.0                     0.5  ...       1.932469   \n",
       "3                          218.0                     0.2  ...       2.088907   \n",
       "4                          216.0                     0.2  ...       2.604232   \n",
       "5                            2.0                     0.3  ...       2.687052   \n",
       "6                            8.0                     0.3  ...       2.677850   \n",
       "7                            4.0                     0.8  ...       2.549019   \n",
       "8                          342.0                     0.7  ...       2.226941   \n",
       "9                          352.0                     1.3  ...       1.996885   \n",
       "\n",
       "   target_4_8003  target_5_6006  target_7_57  target_8_57  target_8_4002  \\\n",
       "0            NaN            NaN     5.130631     1.341606       2.138792   \n",
       "1            NaN            NaN     5.130631     1.195779       2.722099   \n",
       "2            NaN            NaN     5.136395     1.409658       3.110970   \n",
       "3            NaN            NaN     5.217102     1.477711       2.041574   \n",
       "4            NaN            NaN     5.217102     1.458267       2.138792   \n",
       "5            NaN            NaN     5.170984     1.604094       2.236010   \n",
       "6            NaN            NaN     2.951554     1.555485       1.652703   \n",
       "7            NaN            NaN     2.951554     1.711033       1.458267   \n",
       "8            NaN            NaN     2.928495     1.623537       1.361049   \n",
       "9            NaN            NaN     1.815897     1.380493       1.263832   \n",
       "\n",
       "   target_8_6004  target_8_8003  target_9_4002  target_9_8003  \n",
       "0       3.013752            NaN       5.679280            NaN  \n",
       "1       3.888712            NaN       7.426751            NaN  \n",
       "2       3.888712            NaN       7.683732            NaN  \n",
       "3       3.208188            NaN       4.831243            NaN  \n",
       "4       3.499841            NaN       4.625658            NaN  \n",
       "5       3.305406            NaN       5.833469            NaN  \n",
       "6       2.430445            NaN       3.854715            NaN  \n",
       "7       1.361049            NaN       2.595508            NaN  \n",
       "8       1.263832            NaN       2.621206            NaN  \n",
       "9       1.166614            NaN       2.004452            NaN  \n",
       "\n",
       "[10 rows x 95 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37821 entries, 0 to 37820\n",
      "Data columns (total 95 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   rowID                          37821 non-null  int64  \n",
      " 1   chunkID                        37821 non-null  int64  \n",
      " 2   position_within_chunk          37821 non-null  int64  \n",
      " 3   month_most_common              37821 non-null  int64  \n",
      " 4   weekday                        37821 non-null  object \n",
      " 5   hour                           37821 non-null  int64  \n",
      " 6   Solar.radiation_64             37395 non-null  float64\n",
      " 7   WindDirection..Resultant_1     36391 non-null  float64\n",
      " 8   WindDirection..Resultant_1018  9756 non-null   float64\n",
      " 9   WindSpeed..Resultant_1         36391 non-null  float64\n",
      " 10  WindSpeed..Resultant_1018      9756 non-null   float64\n",
      " 11  Ambient.Max.Temperature_14     3219 non-null   float64\n",
      " 12  Ambient.Max.Temperature_22     7224 non-null   float64\n",
      " 13  Ambient.Max.Temperature_50     12368 non-null  float64\n",
      " 14  Ambient.Max.Temperature_52     36460 non-null  float64\n",
      " 15  Ambient.Max.Temperature_57     11926 non-null  float64\n",
      " 16  Ambient.Max.Temperature_76     12249 non-null  float64\n",
      " 17  Ambient.Max.Temperature_2001   12331 non-null  float64\n",
      " 18  Ambient.Max.Temperature_3301   12740 non-null  float64\n",
      " 19  Ambient.Max.Temperature_6005   11427 non-null  float64\n",
      " 20  Ambient.Min.Temperature_14     3219 non-null   float64\n",
      " 21  Ambient.Min.Temperature_22     7272 non-null   float64\n",
      " 22  Ambient.Min.Temperature_50     12649 non-null  float64\n",
      " 23  Ambient.Min.Temperature_52     36743 non-null  float64\n",
      " 24  Ambient.Min.Temperature_57     11926 non-null  float64\n",
      " 25  Ambient.Min.Temperature_76     12502 non-null  float64\n",
      " 26  Ambient.Min.Temperature_2001   12451 non-null  float64\n",
      " 27  Ambient.Min.Temperature_3301   12836 non-null  float64\n",
      " 28  Ambient.Min.Temperature_6005   11538 non-null  float64\n",
      " 29  Sample.Baro.Pressure_14        3219 non-null   float64\n",
      " 30  Sample.Baro.Pressure_22        7206 non-null   float64\n",
      " 31  Sample.Baro.Pressure_50        12629 non-null  float64\n",
      " 32  Sample.Baro.Pressure_52        36743 non-null  float64\n",
      " 33  Sample.Baro.Pressure_57        11815 non-null  float64\n",
      " 34  Sample.Baro.Pressure_76        12526 non-null  float64\n",
      " 35  Sample.Baro.Pressure_2001      12426 non-null  float64\n",
      " 36  Sample.Baro.Pressure_3301      12788 non-null  float64\n",
      " 37  Sample.Baro.Pressure_6005      11492 non-null  float64\n",
      " 38  Sample.Max.Baro.Pressure_14    3219 non-null   float64\n",
      " 39  Sample.Max.Baro.Pressure_22    7176 non-null   float64\n",
      " 40  Sample.Max.Baro.Pressure_50    12605 non-null  float64\n",
      " 41  Sample.Max.Baro.Pressure_52    36695 non-null  float64\n",
      " 42  Sample.Max.Baro.Pressure_57    11791 non-null  float64\n",
      " 43  Sample.Max.Baro.Pressure_76    12526 non-null  float64\n",
      " 44  Sample.Max.Baro.Pressure_2001  12354 non-null  float64\n",
      " 45  Sample.Max.Baro.Pressure_3301  12788 non-null  float64\n",
      " 46  Sample.Max.Baro.Pressure_6005  11437 non-null  float64\n",
      " 47  Sample.Min.Baro.Pressure_14    3219 non-null   float64\n",
      " 48  Sample.Min.Baro.Pressure_22    6962 non-null   float64\n",
      " 49  Sample.Min.Baro.Pressure_50    12509 non-null  float64\n",
      " 50  Sample.Min.Baro.Pressure_52    36743 non-null  float64\n",
      " 51  Sample.Min.Baro.Pressure_57    11815 non-null  float64\n",
      " 52  Sample.Min.Baro.Pressure_76    12526 non-null  float64\n",
      " 53  Sample.Min.Baro.Pressure_2001  12342 non-null  float64\n",
      " 54  Sample.Min.Baro.Pressure_3301  12740 non-null  float64\n",
      " 55  Sample.Min.Baro.Pressure_6005  11429 non-null  float64\n",
      " 56  target_1_57                    5694 non-null   float64\n",
      " 57  target_10_4002                 37011 non-null  float64\n",
      " 58  target_10_8003                 1744 non-null   float64\n",
      " 59  target_11_1                    28580 non-null  float64\n",
      " 60  target_11_32                   21918 non-null  float64\n",
      " 61  target_11_50                   5551 non-null   float64\n",
      " 62  target_11_64                   37388 non-null  float64\n",
      " 63  target_11_1003                 21878 non-null  float64\n",
      " 64  target_11_1601                 30786 non-null  float64\n",
      " 65  target_11_4002                 22226 non-null  float64\n",
      " 66  target_11_8003                 1142 non-null   float64\n",
      " 67  target_14_4002                 37011 non-null  float64\n",
      " 68  target_14_8003                 1744 non-null   float64\n",
      " 69  target_15_57                   5694 non-null   float64\n",
      " 70  target_2_57                    9836 non-null   float64\n",
      " 71  target_3_1                     19288 non-null  float64\n",
      " 72  target_3_50                    1015 non-null   float64\n",
      " 73  target_3_57                    19402 non-null  float64\n",
      " 74  target_3_1601                  4923 non-null   float64\n",
      " 75  target_3_4002                  4509 non-null   float64\n",
      " 76  target_3_6006                  19574 non-null  float64\n",
      " 77  target_4_1                     34695 non-null  float64\n",
      " 78  target_4_50                    33340 non-null  float64\n",
      " 79  target_4_57                    34648 non-null  float64\n",
      " 80  target_4_1018                  9861 non-null   float64\n",
      " 81  target_4_1601                  37472 non-null  float64\n",
      " 82  target_4_2001                  5511 non-null   float64\n",
      " 83  target_4_4002                  36661 non-null  float64\n",
      " 84  target_4_4101                  8902 non-null   float64\n",
      " 85  target_4_6006                  35241 non-null  float64\n",
      " 86  target_4_8003                  1744 non-null   float64\n",
      " 87  target_5_6006                  6649 non-null   float64\n",
      " 88  target_7_57                    5694 non-null   float64\n",
      " 89  target_8_57                    9598 non-null   float64\n",
      " 90  target_8_4002                  37228 non-null  float64\n",
      " 91  target_8_6004                  36831 non-null  float64\n",
      " 92  target_8_8003                  1744 non-null   float64\n",
      " 93  target_9_4002                  37011 non-null  float64\n",
      " 94  target_9_8003                  1744 non-null   float64\n",
      "dtypes: float64(89), int64(5), object(1)\n",
      "memory usage: 27.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# We can see there are quite a lot of missing values\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  how many days? 0\n",
      "1  how many days? 7\n",
      "2  how many days? 6\n",
      "3  how many days? 7\n",
      "4  how many days? 6\n",
      "5  how many days? 7\n",
      "6  how many days? 7\n",
      "7  how many days? 7\n",
      "8  how many days? 7\n",
      "9  how many days? 7\n",
      "10  how many days? 7\n",
      "11  how many days? 7\n",
      "12  how many days? 7\n",
      "13  how many days? 7\n",
      "14  how many days? 6\n",
      "15  how many days? 7\n",
      "16  how many days? 4\n",
      "17  how many days? 7\n",
      "18  how many days? 7\n",
      "19  how many days? 5\n",
      "20  how many days? 7\n",
      "21  how many days? 7\n",
      "22  how many days? 7\n",
      "23  how many days? 7\n",
      "24  how many days? 6\n",
      "25  how many days? 7\n",
      "26  how many days? 7\n",
      "27  how many days? 7\n",
      "28  how many days? 7\n",
      "29  how many days? 6\n",
      "30  how many days? 7\n",
      "31  how many days? 6\n",
      "32  how many days? 6\n",
      "33  how many days? 7\n",
      "34  how many days? 7\n",
      "35  how many days? 7\n",
      "36  how many days? 6\n",
      "37  how many days? 7\n",
      "38  how many days? 7\n",
      "39  how many days? 7\n",
      "40  how many days? 7\n",
      "41  how many days? 7\n",
      "42  how many days? 7\n",
      "43  how many days? 7\n",
      "44  how many days? 7\n",
      "45  how many days? 7\n",
      "46  how many days? 7\n",
      "47  how many days? 7\n",
      "48  how many days? 7\n",
      "49  how many days? 7\n",
      "50  how many days? 5\n",
      "51  how many days? 7\n",
      "52  how many days? 7\n",
      "53  how many days? 7\n",
      "54  how many days? 7\n",
      "55  how many days? 7\n",
      "56  how many days? 7\n",
      "57  how many days? 7\n",
      "58  how many days? 7\n",
      "59  how many days? 7\n",
      "60  how many days? 4\n",
      "61  how many days? 7\n",
      "62  how many days? 6\n",
      "63  how many days? 7\n",
      "64  how many days? 7\n",
      "65  how many days? 7\n",
      "66  how many days? 7\n",
      "67  how many days? 7\n",
      "68  how many days? 6\n",
      "69  how many days? 2\n",
      "70  how many days? 7\n",
      "71  how many days? 7\n",
      "72  how many days? 7\n",
      "73  how many days? 7\n",
      "74  how many days? 7\n",
      "75  how many days? 7\n",
      "76  how many days? 7\n",
      "77  how many days? 6\n",
      "78  how many days? 7\n",
      "79  how many days? 6\n",
      "80  how many days? 7\n",
      "81  how many days? 7\n",
      "82  how many days? 7\n",
      "83  how many days? 7\n",
      "84  how many days? 7\n",
      "85  how many days? 7\n",
      "86  how many days? 7\n",
      "87  how many days? 7\n",
      "88  how many days? 7\n",
      "89  how many days? 7\n",
      "90  how many days? 7\n",
      "91  how many days? 7\n",
      "92  how many days? 7\n",
      "93  how many days? 7\n",
      "94  how many days? 0\n",
      "95  how many days? 7\n",
      "96  how many days? 7\n",
      "97  how many days? 7\n",
      "98  how many days? 7\n",
      "99  how many days? 7\n",
      "100  how many days? 7\n",
      "101  how many days? 7\n",
      "102  how many days? 7\n",
      "103  how many days? 5\n",
      "104  how many days? 7\n",
      "105  how many days? 7\n",
      "106  how many days? 7\n",
      "107  how many days? 7\n",
      "108  how many days? 7\n",
      "109  how many days? 6\n",
      "110  how many days? 7\n",
      "111  how many days? 6\n",
      "112  how many days? 7\n",
      "113  how many days? 7\n",
      "114  how many days? 7\n",
      "115  how many days? 7\n",
      "116  how many days? 7\n",
      "117  how many days? 5\n",
      "118  how many days? 7\n",
      "119  how many days? 6\n",
      "120  how many days? 7\n",
      "121  how many days? 5\n",
      "122  how many days? 7\n",
      "123  how many days? 7\n",
      "124  how many days? 7\n",
      "125  how many days? 7\n",
      "126  how many days? 7\n",
      "127  how many days? 7\n",
      "128  how many days? 7\n",
      "129  how many days? 5\n",
      "130  how many days? 7\n",
      "131  how many days? 7\n",
      "132  how many days? 7\n",
      "133  how many days? 6\n",
      "134  how many days? 7\n",
      "135  how many days? 7\n",
      "136  how many days? 7\n",
      "137  how many days? 7\n",
      "138  how many days? 7\n",
      "139  how many days? 7\n",
      "140  how many days? 7\n",
      "141  how many days? 7\n",
      "142  how many days? 7\n",
      "143  how many days? 7\n",
      "144  how many days? 7\n",
      "145  how many days? 7\n",
      "146  how many days? 7\n",
      "147  how many days? 7\n",
      "148  how many days? 7\n",
      "149  how many days? 6\n",
      "150  how many days? 7\n",
      "151  how many days? 7\n",
      "152  how many days? 7\n",
      "153  how many days? 0\n",
      "154  how many days? 7\n",
      "155  how many days? 4\n",
      "156  how many days? 7\n",
      "157  how many days? 7\n",
      "158  how many days? 5\n",
      "159  how many days? 7\n",
      "160  how many days? 7\n",
      "161  how many days? 7\n",
      "162  how many days? 5\n",
      "163  how many days? 5\n",
      "164  how many days? 7\n",
      "165  how many days? 7\n",
      "166  how many days? 7\n",
      "167  how many days? 7\n",
      "168  how many days? 7\n",
      "169  how many days? 7\n",
      "170  how many days? 6\n",
      "171  how many days? 6\n",
      "172  how many days? 7\n",
      "173  how many days? 6\n",
      "174  how many days? 7\n",
      "175  how many days? 7\n",
      "176  how many days? 7\n",
      "177  how many days? 7\n",
      "178  how many days? 6\n",
      "179  how many days? 7\n",
      "180  how many days? 5\n",
      "181  how many days? 6\n",
      "182  how many days? 7\n",
      "183  how many days? 7\n",
      "184  how many days? 6\n",
      "185  how many days? 7\n",
      "186  how many days? 7\n",
      "187  how many days? 6\n",
      "188  how many days? 7\n",
      "189  how many days? 7\n",
      "190  how many days? 7\n",
      "191  how many days? 7\n",
      "192  how many days? 5\n",
      "193  how many days? 7\n",
      "194  how many days? 7\n",
      "195  how many days? 7\n",
      "196  how many days? 7\n",
      "197  how many days? 7\n",
      "198  how many days? 7\n",
      "199  how many days? 7\n",
      "200  how many days? 7\n",
      "201  how many days? 7\n",
      "202  how many days? 7\n",
      "203  how many days? 7\n",
      "204  how many days? 7\n",
      "205  how many days? 7\n",
      "206  how many days? 7\n",
      "207  how many days? 7\n",
      "208  how many days? 7\n",
      "209  how many days? 7\n",
      "210  how many days? 7\n"
     ]
    }
   ],
   "source": [
    "# How many days are there in each chunk?\n",
    "for i in range(211):\n",
    "    print(i, \" how many days?\", len(dataset[dataset[\"chunkID\"] == i][\"weekday\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  how many days? 0\n",
      "1  how many days? 192\n",
      "2  how many days? 168\n",
      "3  how many days? 192\n",
      "4  how many days? 144\n",
      "5  how many days? 192\n",
      "6  how many days? 192\n",
      "7  how many days? 192\n",
      "8  how many days? 192\n",
      "9  how many days? 192\n",
      "10  how many days? 192\n",
      "11  how many days? 192\n",
      "12  how many days? 192\n",
      "13  how many days? 192\n",
      "14  how many days? 168\n",
      "15  how many days? 192\n",
      "16  how many days? 89\n",
      "17  how many days? 192\n",
      "18  how many days? 192\n",
      "19  how many days? 120\n",
      "20  how many days? 168\n",
      "21  how many days? 168\n",
      "22  how many days? 192\n",
      "23  how many days? 192\n",
      "24  how many days? 134\n",
      "25  how many days? 192\n",
      "26  how many days? 192\n",
      "27  how many days? 192\n",
      "28  how many days? 192\n",
      "29  how many days? 165\n",
      "30  how many days? 192\n",
      "31  how many days? 168\n",
      "32  how many days? 168\n",
      "33  how many days? 192\n",
      "34  how many days? 192\n",
      "35  how many days? 192\n",
      "36  how many days? 168\n",
      "37  how many days? 192\n",
      "38  how many days? 192\n",
      "39  how many days? 192\n",
      "40  how many days? 175\n",
      "41  how many days? 192\n",
      "42  how many days? 192\n",
      "43  how many days? 192\n",
      "44  how many days? 192\n",
      "45  how many days? 192\n",
      "46  how many days? 192\n",
      "47  how many days? 168\n",
      "48  how many days? 192\n",
      "49  how many days? 192\n",
      "50  how many days? 139\n",
      "51  how many days? 192\n",
      "52  how many days? 192\n",
      "53  how many days? 192\n",
      "54  how many days? 192\n",
      "55  how many days? 192\n",
      "56  how many days? 192\n",
      "57  how many days? 192\n",
      "58  how many days? 192\n",
      "59  how many days? 192\n",
      "60  how many days? 120\n",
      "61  how many days? 192\n",
      "62  how many days? 144\n",
      "63  how many days? 192\n",
      "64  how many days? 192\n",
      "65  how many days? 192\n",
      "66  how many days? 192\n",
      "67  how many days? 174\n",
      "68  how many days? 168\n",
      "69  how many days? 28\n",
      "70  how many days? 192\n",
      "71  how many days? 192\n",
      "72  how many days? 192\n",
      "73  how many days? 192\n",
      "74  how many days? 192\n",
      "75  how many days? 192\n",
      "76  how many days? 181\n",
      "77  how many days? 164\n",
      "78  how many days? 192\n",
      "79  how many days? 168\n",
      "80  how many days? 192\n",
      "81  how many days? 168\n",
      "82  how many days? 192\n",
      "83  how many days? 192\n",
      "84  how many days? 192\n",
      "85  how many days? 168\n",
      "86  how many days? 187\n",
      "87  how many days? 192\n",
      "88  how many days? 192\n",
      "89  how many days? 192\n",
      "90  how many days? 192\n",
      "91  how many days? 192\n",
      "92  how many days? 192\n",
      "93  how many days? 192\n",
      "94  how many days? 0\n",
      "95  how many days? 192\n",
      "96  how many days? 192\n",
      "97  how many days? 192\n",
      "98  how many days? 168\n",
      "99  how many days? 192\n",
      "100  how many days? 192\n",
      "101  how many days? 192\n",
      "102  how many days? 192\n",
      "103  how many days? 144\n",
      "104  how many days? 192\n",
      "105  how many days? 192\n",
      "106  how many days? 168\n",
      "107  how many days? 192\n",
      "108  how many days? 192\n",
      "109  how many days? 168\n",
      "110  how many days? 168\n",
      "111  how many days? 168\n",
      "112  how many days? 192\n",
      "113  how many days? 192\n",
      "114  how many days? 192\n",
      "115  how many days? 192\n",
      "116  how many days? 192\n",
      "117  how many days? 144\n",
      "118  how many days? 177\n",
      "119  how many days? 148\n",
      "120  how many days? 192\n",
      "121  how many days? 132\n",
      "122  how many days? 192\n",
      "123  how many days? 183\n",
      "124  how many days? 192\n",
      "125  how many days? 192\n",
      "126  how many days? 192\n",
      "127  how many days? 192\n",
      "128  how many days? 192\n",
      "129  how many days? 144\n",
      "130  how many days? 192\n",
      "131  how many days? 192\n",
      "132  how many days? 192\n",
      "133  how many days? 168\n",
      "134  how many days? 192\n",
      "135  how many days? 192\n",
      "136  how many days? 192\n",
      "137  how many days? 192\n",
      "138  how many days? 192\n",
      "139  how many days? 178\n",
      "140  how many days? 192\n",
      "141  how many days? 192\n",
      "142  how many days? 192\n",
      "143  how many days? 192\n",
      "144  how many days? 192\n",
      "145  how many days? 192\n",
      "146  how many days? 192\n",
      "147  how many days? 192\n",
      "148  how many days? 192\n",
      "149  how many days? 168\n",
      "150  how many days? 192\n",
      "151  how many days? 192\n",
      "152  how many days? 192\n",
      "153  how many days? 0\n",
      "154  how many days? 192\n",
      "155  how many days? 85\n",
      "156  how many days? 192\n",
      "157  how many days? 192\n",
      "158  how many days? 113\n",
      "159  how many days? 192\n",
      "160  how many days? 192\n",
      "161  how many days? 192\n",
      "162  how many days? 120\n",
      "163  how many days? 144\n",
      "164  how many days? 192\n",
      "165  how many days? 192\n",
      "166  how many days? 192\n",
      "167  how many days? 192\n",
      "168  how many days? 192\n",
      "169  how many days? 192\n",
      "170  how many days? 168\n",
      "171  how many days? 168\n",
      "172  how many days? 192\n",
      "173  how many days? 168\n",
      "174  how many days? 192\n",
      "175  how many days? 192\n",
      "176  how many days? 192\n",
      "177  how many days? 192\n",
      "178  how many days? 168\n",
      "179  how many days? 192\n",
      "180  how many days? 144\n",
      "181  how many days? 168\n",
      "182  how many days? 192\n",
      "183  how many days? 192\n",
      "184  how many days? 122\n",
      "185  how many days? 192\n",
      "186  how many days? 192\n",
      "187  how many days? 168\n",
      "188  how many days? 168\n",
      "189  how many days? 192\n",
      "190  how many days? 192\n",
      "191  how many days? 192\n",
      "192  how many days? 144\n",
      "193  how many days? 192\n",
      "194  how many days? 183\n",
      "195  how many days? 192\n",
      "196  how many days? 192\n",
      "197  how many days? 192\n",
      "198  how many days? 192\n",
      "199  how many days? 192\n",
      "200  how many days? 192\n",
      "201  how many days? 192\n",
      "202  how many days? 192\n",
      "203  how many days? 192\n",
      "204  how many days? 192\n",
      "205  how many days? 192\n",
      "206  how many days? 192\n",
      "207  how many days? 192\n",
      "208  how many days? 192\n",
      "209  how many days? 192\n",
      "210  how many days? 192\n"
     ]
    }
   ],
   "source": [
    "# How many days are there in each chunk? 192 (8 days * 24 hours), that is why we say there are 8 days.\n",
    "for i in range(211):\n",
    "    print(i, \" how many days?\", len(dataset[dataset[\"chunkID\"] == i][\"position_within_chunk\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- When working with the **naive models**, we are only interested in the target variables, and **none** of the input meteorological variables. \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_1_57</th>\n",
       "      <th>target_10_4002</th>\n",
       "      <th>target_10_8003</th>\n",
       "      <th>target_11_1</th>\n",
       "      <th>target_11_32</th>\n",
       "      <th>target_11_50</th>\n",
       "      <th>target_11_64</th>\n",
       "      <th>target_11_1003</th>\n",
       "      <th>target_11_1601</th>\n",
       "      <th>target_11_4002</th>\n",
       "      <th>...</th>\n",
       "      <th>target_4_6006</th>\n",
       "      <th>target_4_8003</th>\n",
       "      <th>target_5_6006</th>\n",
       "      <th>target_7_57</th>\n",
       "      <th>target_8_57</th>\n",
       "      <th>target_8_4002</th>\n",
       "      <th>target_8_6004</th>\n",
       "      <th>target_8_8003</th>\n",
       "      <th>target_9_4002</th>\n",
       "      <th>target_9_8003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.679233</td>\n",
       "      <td>6.181623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>1.748424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.130631</td>\n",
       "      <td>1.341606</td>\n",
       "      <td>2.138792</td>\n",
       "      <td>3.013752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.679280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.679233</td>\n",
       "      <td>8.475833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>2.144120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.130631</td>\n",
       "      <td>1.195779</td>\n",
       "      <td>2.722099</td>\n",
       "      <td>3.888712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.426751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.679233</td>\n",
       "      <td>8.921930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>1.932469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.136395</td>\n",
       "      <td>1.409658</td>\n",
       "      <td>3.110970</td>\n",
       "      <td>3.888712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.683732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.679233</td>\n",
       "      <td>5.098246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>2.088907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.217102</td>\n",
       "      <td>1.477711</td>\n",
       "      <td>2.041574</td>\n",
       "      <td>3.208188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.831243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.679233</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.217102</td>\n",
       "      <td>1.458267</td>\n",
       "      <td>2.138792</td>\n",
       "      <td>3.499841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.625658</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37816</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.919801</td>\n",
       "      <td>1.782115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.609652</td>\n",
       "      <td>1.322214</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.574876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.453953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642453</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.804826</td>\n",
       "      <td>1.724628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.379702</td>\n",
       "      <td>0.747339</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.599878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002226</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689851</td>\n",
       "      <td>1.609652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632363</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.287438</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.599878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822339</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.286776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.459901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.092264</td>\n",
       "      <td>0.919801</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.459901</td>\n",
       "      <td>...</td>\n",
       "      <td>1.058257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862314</td>\n",
       "      <td>1.034777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977289</td>\n",
       "      <td>1.322214</td>\n",
       "      <td>0.402413</td>\n",
       "      <td>0.632363</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.266409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.436868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37821 rows × 39 columns</p>\n",
""      ],
      "text/plain": [
       "       target_1_57  target_10_4002  target_10_8003  target_11_1  target_11_32  \\\n",
       "0         2.679233        6.181623             NaN     0.114975      0.114975   \n",
       "1         2.679233        8.475833             NaN     0.114975      0.114975   \n",
       "2         2.679233        8.921930             NaN     0.114975      0.114975   \n",
       "3         2.679233        5.098246             NaN     0.114975      0.114975   \n",
       "4         2.679233        4.875197             NaN     0.114975      0.114975   \n",
       "...            ...             ...             ...          ...           ...   \n",
       "37816          NaN        0.095592             NaN     0.919801      1.782115   \n",
       "37817          NaN        0.350504             NaN     0.804826      1.724628   \n",
       "37818          NaN        0.254912             NaN     0.689851      1.609652   \n",
       "37819          NaN        0.286776             NaN     0.459901           NaN   \n",
       "37820          NaN        0.159320             NaN     0.862314      1.034777   \n",
       "\n",
       "       target_11_50  target_11_64  target_11_1003  target_11_1601  \\\n",
       "0          0.114975      0.114975        0.114975        0.114975   \n",
       "1          0.114975      0.114975        0.114975        0.114975   \n",
       "2          0.114975      0.114975        0.114975        0.114975   \n",
       "3          0.114975      0.114975        0.114975        0.114975   \n",
       "4          0.114975      0.114975        0.114975        0.114975   \n",
       "...             ...           ...             ...             ...   \n",
       "37816           NaN      1.609652        1.322214        0.114975   \n",
       "37817           NaN      1.379702        0.747339        0.114975   \n",
       "37818           NaN           NaN        0.632363        0.114975   \n",
       "37819           NaN      1.092264        0.919801        0.114975   \n",
       "37820           NaN      0.977289        1.322214        0.402413   \n",
       "\n",
       "       target_11_4002  ...  target_4_6006  target_4_8003  target_5_6006  \\\n",
       "0            0.114975  ...       1.748424            NaN            NaN   \n",
       "1            0.114975  ...       2.144120            NaN            NaN   \n",
       "2            0.114975  ...       1.932469            NaN            NaN   \n",
       "3            0.114975  ...       2.088907            NaN            NaN   \n",
       "4            0.114975  ...       2.604232            NaN            NaN   \n",
       "...               ...  ...            ...            ...            ...   \n",
       "37816        0.574876  ...       1.453953            NaN       0.933143   \n",
       "37817        0.114975  ...       1.076661            NaN       0.599878   \n",
       "37818        0.287438  ...       1.113470            NaN       0.599878   \n",
       "37819        0.459901  ...       1.058257            NaN       0.666531   \n",
       "37820        0.632363  ...       1.573582            NaN       1.266409   \n",
       "\n",
       "       target_7_57  target_8_57  target_8_4002  target_8_6004  target_8_8003  \\\n",
       "0         5.130631     1.341606       2.138792       3.013752            NaN   \n",
       "1         5.130631     1.195779       2.722099       3.888712            NaN   \n",
       "2         5.136395     1.409658       3.110970       3.888712            NaN   \n",
       "3         5.217102     1.477711       2.041574       3.208188            NaN   \n",
       "4         5.217102     1.458267       2.138792       3.499841            NaN   \n",
       "...            ...          ...            ...            ...            ...   \n",
       "37816          NaN          NaN       0.291653       0.291653            NaN   \n",
       "37817          NaN          NaN       0.291653       0.291653            NaN   \n",
       "37818          NaN          NaN       0.291653       0.291653            NaN   \n",
       "37819          NaN          NaN       0.291653       0.291653            NaN   \n",
       "37820          NaN          NaN       0.291653       0.291653            NaN   \n",
       "\n",
       "       target_9_4002  target_9_8003  \n",
       "0           5.679280            NaN  \n",
       "1           7.426751            NaN  \n",
       "2           7.683732            NaN  \n",
       "3           4.831243            NaN  \n",
       "4           4.625658            NaN  \n",
       "...              ...            ...  \n",
       "37816       0.642453            NaN  \n",
       "37817       1.002226            NaN  \n",
       "37818       0.822339            NaN  \n",
       "37819       0.719547            NaN  \n",
       "37820       0.436868            NaN  \n",
       "\n",
       "[37821 rows x 39 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many target variables do we have?\n",
    "dataset.filter(regex = 'target_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by chunks\n",
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37821, 95)\n",
      "(37821, 95)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "       20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
       "       71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87,\n",
       "       88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chunk_ids = dataset[\"chunkID\"].unique()\n",
    "chunk_ids = unique(values[:, 1])\n",
    "chunk_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We can group data by the ‘chunkID’ variable.\n",
    "- To do so a function is created.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset by 'chunkID', return a dict of id to rows\n",
    "def to_chunks(values, chunk_ix=1):\n",
    "    \"\"\"Split the dataset into chunks.\n",
    "    \n",
    "    Returns a dict of ID to rows\n",
    "    \"\"\"\n",
    "    chunks = dict()\n",
    "    # get the unique chunk ids\n",
    "    chunk_ids = unique(values[:, chunk_ix])\n",
    "    # group rows by chunk id\n",
    "    for chunk_id in chunk_ids:\n",
    "        selection = values[:, chunk_ix] == chunk_id\n",
    "        chunks[chunk_id] = values[selection, :]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 208\n"
     ]
    }
   ],
   "source": [
    "chunks = to_chunks(values)\n",
    "print('Total Chunks: %d' % len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26137</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.107311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.486089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.07932</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26138</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>293.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.410985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.486089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848037</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26139</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.613434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.583307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26140</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.226941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.680525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.796641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26141</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.199334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.972178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.053622</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>26324</td>\n",
       "      <td>100</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.205421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>26325</td>\n",
       "      <td>100</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>314.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.570467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41117</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>26326</td>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.248388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.359773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>26327</td>\n",
       "      <td>100</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>322.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.944715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.436868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>26328</td>\n",
       "      <td>100</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>311.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.368017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 95 columns</p>\n",
""      ],
      "text/plain": [
       "        0    1    2  3         4   5     6      7    8    9   ...        85  \\\n",
       "0    26137  100    1  1  Thursday   2  0.01  278.0  NaN  4.1  ...  2.107311   \n",
       "1    26138  100    2  1  Thursday   3  0.01  293.0  NaN  3.7  ...  2.410985   \n",
       "2    26139  100    3  1  Thursday   4  0.01  278.0  NaN  2.9  ...  2.613434   \n",
       "3    26140  100    4  1  Thursday   5  0.01  252.0  NaN  4.0  ...  2.226941   \n",
       "4    26141  100    5  1  Thursday   6  0.01  260.0  NaN  4.3  ...  2.199334   \n",
       "..     ...  ...  ... ..       ...  ..   ...    ...  ...  ...  ...       ...   \n",
       "187  26324  100  188  1  Thursday  21  0.01  290.0  NaN  4.4  ...  4.205421   \n",
       "188  26325  100  189  1  Thursday  22  0.01  314.0  NaN  6.4  ...  3.570467   \n",
       "189  26326  100  190  1  Thursday  23  0.01  320.0  NaN  5.6  ...  3.248388   \n",
       "190  26327  100  191  1    Friday   0  0.01  322.0  NaN  5.1  ...  2.944715   \n",
       "191  26328  100  192  1    Friday   1  0.01  311.0  NaN  4.0  ...  3.368017   \n",
       "\n",
       "      86   87   88   89        90        91   92        93   94  \n",
       "0    NaN  NaN  NaN  NaN  0.291653  0.486089  NaN   1.07932  NaN  \n",
       "1    NaN  NaN  NaN  NaN  0.291653  0.486089  NaN  0.848037  NaN  \n",
       "2    NaN  NaN  NaN  NaN  0.291653  0.583307  NaN  0.925132  NaN  \n",
       "3    NaN  NaN  NaN  NaN  0.291653  0.680525  NaN  0.796641  NaN  \n",
       "4    NaN  NaN  NaN  NaN  0.291653  0.972178  NaN  1.053622  NaN  \n",
       "..   ...  ...  ...  ...       ...       ...  ...       ...  ...  \n",
       "187  NaN  NaN  NaN  NaN  0.291653  0.291653  NaN  0.719547  NaN  \n",
       "188  NaN  NaN  NaN  NaN  0.291653  0.291653  NaN   0.41117  NaN  \n",
       "189  NaN  NaN  NaN  NaN  0.291653  0.291653  NaN  0.359773  NaN  \n",
       "190  NaN  NaN  NaN  NaN  0.291653  0.291653  NaN  0.436868  NaN  \n",
       "191  NaN  NaN  NaN  NaN  0.291653  0.291653  NaN  0.334075  NaN  \n",
       "\n",
       "[192 rows x 95 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the 100th chunk\n",
    "pd.DataFrame(chunks[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
       "       'Wednesday'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I still see a cycle of 7 days not 8!\n",
    "unique(pd.DataFrame(chunks[100][:,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Each chunk covers an interval of **8** days of hourly observations, although the number of actual observations within each chunk may vary widely.\n",
    "- We can split each chunk into the first **5** days of observations for training and the last three for test.\n",
    "- Each observation has a row called ‘position_within_chunk‘ that varies from 1 to 192 (**8 days * 24 hours**). We can therefore take all rows with a value in this column that is less than or equal to 120 (5 * 24) as training data and any values more than 120 as test data.\n",
    "- Further, any chunks that don’t have any observations in the train or test split can be dropped as not viable.\n",
    "- We do not require the entire test dataset; instead, we only require the observations at specific lead times over the three day period, specifically the lead times: `+1, +2, +3, +4, +5, +10, +17, +24, +48, +72`\n",
    "\n",
    "- When working with the **naive models**, we are only interested in the target variables, and **none** of the input meteorological variables. \n",
    "- Therefore, we can remove the input data and have the train and test data **only** comprised of the 39 target variables for each chunk, as well as the position within chunk and hour of observation.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each chunk into train/test sets\n",
    "def split_train_test(chunks, row_in_chunk_ix=2):\n",
    "    train, test = list(), list()\n",
    "    # first 5 days of hourly observations for train\n",
    "    cut_point = 5 * 24\n",
    "    # enumerate chunks\n",
    "    for k,rows in chunks.items():\n",
    "        # split chunk rows by 'position_within_chunk'\n",
    "        train_rows = rows[rows[:,row_in_chunk_ix] <= cut_point, :]\n",
    "        test_rows = rows[rows[:,row_in_chunk_ix] > cut_point, :]\n",
    "        if len(train_rows) == 0 or len(test_rows) == 0:\n",
    "            print('>dropping chunk=%d: train=%s, test=%s' % (k, train_rows.shape, test_rows.shape))\n",
    "            continue\n",
    "        # store with chunk id, position in chunk, hour and all targets\n",
    "        indices = [1,2,5] + [x for x in range(56,train_rows.shape[1])]\n",
    "        train.append(train_rows[:, indices])\n",
    "        test.append(test_rows[:, indices])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a list of relative forecast lead times\n",
    "def get_lead_times():\n",
    "    return [1, 2 ,3, 4, 5, 10, 17, 24, 48, 72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the rows in a test chunk to forecasts\n",
    "def to_forecasts(test_chunks, row_in_chunk_ix=1):\n",
    "    # get lead times\n",
    "    lead_times = get_lead_times()\n",
    "    # first 5 days of hourly observations for train\n",
    "    cut_point = 5 * 24\n",
    "    forecasts = list()\n",
    "    # enumerate each chunk\n",
    "    for rows in test_chunks:\n",
    "        chunk_id = rows[0, 0]\n",
    "        # enumerate each lead time\n",
    "        for tau in lead_times:\n",
    "            # determine the row in chunk we want for the lead time\n",
    "            offset = cut_point + tau\n",
    "            # retrieve data for the lead time using row number in chunk\n",
    "            row_for_tau = rows[rows[:,row_in_chunk_ix]==offset, :]\n",
    "            # check if we have data\n",
    "            if len(row_for_tau) == 0:\n",
    "                # create a mock row [chunk, position, hour] + [nan...]\n",
    "                row = [chunk_id, offset, nan] + [nan for _ in range(39)]\n",
    "                forecasts.append(row)\n",
    "            else:\n",
    "                # store the forecast row\n",
    "                forecasts.append(row_for_tau[0])\n",
    "    return array(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">dropping chunk=69: train=(0, 95), test=(28, 95)\n",
      "Train Rows: (23514, 42)\n",
      "Test Rows: (2070, 42)\n"
     ]
    }
   ],
   "source": [
    "# split into train/test\n",
    "train, test = split_train_test(chunks)\n",
    "\n",
    "# flatten training chunks to rows\n",
    "train_rows = array([row for rows in train for row in rows])\n",
    "\n",
    "# print(train_rows.shape)\n",
    "print('Train Rows: %s' % str(train_rows.shape))\n",
    "\n",
    "# reduce train to forecast lead times only\n",
    "test_rows = to_forecasts(test)\n",
    "print('Test Rows: %s' % str(test_rows.shape))\n",
    "\n",
    "# save datasets\n",
    "#savetxt('AirQualityPrediction/naive_train.csv', train_rows, delimiter=',')\n",
    "#savetxt('AirQualityPrediction/naive_test.csv', test_rows, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We can then see that we have **42** columns in each of the train and test sets, one for the chunk id, position within chunk, hour of day, and the **39** training variables. \n",
    "- Please note that we still I have not taken care of the **NaN** entries.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>21</td>\n",
       "      <td>7.109461</td>\n",
       "      <td>3.409452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.344926</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>4.205421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.217472</td>\n",
       "      <td>7.91353</td>\n",
       "      <td>1.652703</td>\n",
       "      <td>2.722099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.163092</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>22</td>\n",
       "      <td>7.109461</td>\n",
       "      <td>2.995219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.402413</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>3.37722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.211707</td>\n",
       "      <td>8.875986</td>\n",
       "      <td>1.458267</td>\n",
       "      <td>2.430445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.751923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>23</td>\n",
       "      <td>7.067268</td>\n",
       "      <td>3.47318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>3.653287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.223236</td>\n",
       "      <td>9.39124</td>\n",
       "      <td>1.555485</td>\n",
       "      <td>2.138792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0603</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>5.252984</td>\n",
       "      <td>4.046732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>4.012174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.684417</td>\n",
       "      <td>8.137131</td>\n",
       "      <td>1.652703</td>\n",
       "      <td>1.847138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.394375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>5.252984</td>\n",
       "      <td>4.684013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>...</td>\n",
       "      <td>4.122601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.678652</td>\n",
       "      <td>8.730159</td>\n",
       "      <td>1.749921</td>\n",
       "      <td>1.555485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.856941</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>210</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.839603</td>\n",
       "      <td>2.529454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.356991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.266612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.256981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>210</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.494677</td>\n",
       "      <td>1.954578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.839603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.86649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.282679</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>210</td>\n",
       "      <td>144</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632363</td>\n",
       "      <td>1.207239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>210</td>\n",
       "      <td>168</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.127041</td>\n",
       "      <td>2.701916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.414479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.266612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.565358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>210</td>\n",
       "      <td>192</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862314</td>\n",
       "      <td>1.034777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977289</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.266409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>0.291653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.436868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2070 rows × 42 columns</p>\n",
""      ],
      "text/plain": [
       "       0    1   2         3         4    5         6         7         8   \\\n",
       "0       1  121  21  7.109461  3.409452  NaN  0.114975  0.344926  0.114975   \n",
       "1       1  122  22  7.109461  2.995219  NaN  0.114975  0.402413  0.114975   \n",
       "2       1  123  23  7.067268   3.47318  NaN  0.114975  0.114975  0.114975   \n",
       "3       1  124   0  5.252984  4.046732  NaN  0.114975  0.114975  0.114975   \n",
       "4       1  125   1  5.252984  4.684013  NaN  0.114975  0.114975  0.114975   \n",
       "...   ...  ...  ..       ...       ...  ...       ...       ...       ...   \n",
       "2065  210  130  18       NaN       0.0  NaN  1.839603  2.529454       NaN   \n",
       "2066  210  137   1       NaN       0.0  NaN  1.494677  1.954578       NaN   \n",
       "2067  210  144   8       NaN  0.063728  NaN  0.632363  1.207239       NaN   \n",
       "2068  210  168   8       NaN  0.095592  NaN  2.127041  2.701916       NaN   \n",
       "2069  210  192   8       NaN   0.15932  NaN  0.862314  1.034777       NaN   \n",
       "\n",
       "            9   ...        32   33        34        35        36        37  \\\n",
       "0     0.114975  ...  4.205421  NaN       NaN  7.217472   7.91353  1.652703   \n",
       "1     0.114975  ...   3.37722  NaN       NaN  7.211707  8.875986  1.458267   \n",
       "2     0.114975  ...  3.653287  NaN       NaN  7.223236   9.39124  1.555485   \n",
       "3     0.114975  ...  4.012174  NaN       NaN  7.684417  8.137131  1.652703   \n",
       "4     0.114975  ...  4.122601  NaN       NaN  7.678652  8.730159  1.749921   \n",
       "...        ...  ...       ...  ...       ...       ...       ...       ...   \n",
       "2065  2.356991  ...  0.800594  NaN  0.266612       NaN       NaN  0.291653   \n",
       "2066  1.839603  ...  0.156438  NaN   0.86649       NaN       NaN  0.291653   \n",
       "2067  0.977289  ...  0.524527  NaN  0.999796       NaN       NaN  0.291653   \n",
       "2068  2.414479  ...  0.257663  NaN  0.266612       NaN       NaN  0.291653   \n",
       "2069  0.977289  ...  1.573582  NaN  1.266409       NaN       NaN  0.291653   \n",
       "\n",
       "            38   39        40   41  \n",
       "0     2.722099  NaN  4.163092  NaN  \n",
       "1     2.430445  NaN  3.751923  NaN  \n",
       "2     2.138792  NaN    4.0603  NaN  \n",
       "3     1.847138  NaN  4.394375  NaN  \n",
       "4     1.555485  NaN  4.856941  NaN  \n",
       "...        ...  ...       ...  ...  \n",
       "2065  0.291653  NaN  0.256981  NaN  \n",
       "2066  0.291653  NaN  0.282679  NaN  \n",
       "2067  0.291653  NaN  0.693849  NaN  \n",
       "2068  0.291653  NaN  0.565358  NaN  \n",
       "2069  0.291653  NaN  0.436868  NaN  \n",
       "\n",
       "[2070 rows x 42 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- It is helpful to have a simpler format when evaluating forecasts. \n",
    "- For example, we will use the three-dimensional structure of `[chunks, variables, time]`, where variable is the target variable number from 0 to 38 and time is the lead time index from 0 to 9\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_forecasts(test_chunks):\n",
    "    \"\"\"Prepare test forecast\n",
    "    \n",
    "    Convert the test dataset in chunks to [chunk][variable][time] format  \n",
    "    \"\"\"\n",
    "    predictions = list()\n",
    "    # enumerate chunks to forecast\n",
    "    for rows in test_chunks:\n",
    "        # enumerate targets for chunk\n",
    "        chunk_predictions = list()\n",
    "        for j in range(3, rows.shape[1]):\n",
    "            yhat = rows[:, j]\n",
    "            chunk_predictions.append(yhat)\n",
    "        chunk_predictions = array(chunk_predictions)\n",
    "        predictions.append(chunk_predictions)\n",
    "    return array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We will evaluate a model using the mean absolute error, or **MAE**. Where is the mean below?\n",
    "- This is the metric that was used in the competition and is a **sensible choice given the non-Gaussian distribution of the target variables**.\n",
    "\n",
    "\n",
    "- If a lead time contains no data in the test set (e.g. NaN), then no error will be calculated for that forecast. \n",
    "- If the lead time does have data in the test set but no data in the forecast, then the full magnitude of the observation will be taken as error. \n",
    "- Finally, if the test set has an observation and a forecast was made, then the absolute difference will be recorded as the error. \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(actual, predicted):\n",
    "    # give the full actual value if predicted is nan\n",
    "    if isnan(predicted):\n",
    "        return abs(actual)\n",
    "    # calculate abs difference\n",
    "    return abs(actual - predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The overall MAE will be calculated, but we will also calculate a MAE for each forecast lead time. This can help with model selection generally as some models may perform differently at different lead times.\n",
    "\n",
    "- The evaluate_forecasts() function below implements this, calculating the MAE and per-lead time MAE for the provided predictions and expected values in `[chunk, variable, time]` format.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a forecast in the format [chunk][variable][time]\n",
    "def evaluate_forecasts(predictions, testset):\n",
    "    lead_times = get_lead_times()\n",
    "    total_mae, times_mae = 0.0, [0.0 for _ in range(len(lead_times))]\n",
    "    total_c, times_c = 0, [0 for _ in range(len(lead_times))]\n",
    "    # enumerate test chunks\n",
    "    for i in range(len(test_chunks)):\n",
    "        # convert to forecasts\n",
    "        actual = testset[i]\n",
    "        predicted = predictions[i]\n",
    "        # enumerate target variables\n",
    "        for j in range(predicted.shape[0]):\n",
    "            # enumerate lead times\n",
    "            for k in range(len(lead_times)):\n",
    "                # skip if actual in nan\n",
    "                if isnan(actual[j, k]):\n",
    "                    continue\n",
    "                # calculate error\n",
    "                error = calculate_error(actual[j, k], predicted[j, k])\n",
    "                # update statistics\n",
    "                total_mae += error\n",
    "                times_mae[k] += error\n",
    "                total_c += 1\n",
    "                times_c[k] += 1\n",
    "    # normalize summed absolute errors\n",
    "    total_mae /= total_c\n",
    "    times_mae = [times_mae[i]/times_c[i] for i in range(len(times_mae))]\n",
    "    return total_mae, times_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_error(name, total_mae, times_mae):\n",
    "    # print summary\n",
    "    lead_times = get_lead_times()\n",
    "    formatted = ['+%d %.3f' % (lead_times[i], times_mae[i]) for i in range(len(lead_times))]\n",
    "    s_scores = ', '.join(formatted)\n",
    "    print('%s: [%.3f MAE] %s' % (name, total_mae, s_scores))\n",
    "    # plot summary\n",
    "    pyplot.plot([str(x) for x in lead_times], times_mae, marker='.')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Three candidate strategies for dealing with these gaps are as follows:\n",
    "    - Ignore the gaps.\n",
    "    - Use data without gaps.\n",
    "    - Fill the gaps.\n",
    "\n",
    "- Here we'll fill the gap using the median. This is a good choice given the non-normal distribution of the data.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout a variable with breaks in the data for missing positions\n",
    "def variable_to_series(chunk_train, col_ix, n_steps=5*24):\n",
    "    # lay out whole series\n",
    "    data = [nan for _ in range(n_steps)]\n",
    "    # mark all available data\n",
    "    for i in range(len(chunk_train)):\n",
    "        # get position in chunk\n",
    "        position = int(chunk_train[i, 1] - 1)\n",
    "        # store data\n",
    "        data[position] = chunk_train[i, col_ix]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate series of hours (in place) in 24 hour time\n",
    "def interpolate_hours(hours):\n",
    "    # find the first hour\n",
    "    ix = -1\n",
    "    for i in range(len(hours)):\n",
    "        if not isnan(hours[i]):\n",
    "            ix = i\n",
    "            break\n",
    "    # fill-forward\n",
    "    hour = hours[ix]\n",
    "    for i in range(ix+1, len(hours)):\n",
    "        # increment hour\n",
    "        hour += 1\n",
    "        # check for a fill\n",
    "        if isnan(hours[i]):\n",
    "            hours[i] = hour % 24\n",
    "    # fill-backward\n",
    "    hour = hours[ix]\n",
    "    for i in range(ix-1, -1, -1):\n",
    "        # decrement hour\n",
    "        hour -= 1\n",
    "        # check for a fill\n",
    "        if isnan(hours[i]):\n",
    "            hours[i] = hour % 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input-output preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-  \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  7]\n",
      " [ 1  2  8]\n",
      " [ 2  3  9]\n",
      " [ 3  4 10]\n",
      " [ 4  5 11]\n",
      " [ 5  6 12]\n",
      " [ 6  7 13]\n",
      " [ 7  8 14]\n",
      " [ 8  9 15]\n",
      " [ 9 10 16]\n",
      " [10 11 17]\n",
      " [11 12 18]\n",
      " [12 13 19]]\n"
     ]
    }
   ],
   "source": [
    "# test supervised to input/output patterns\n",
    "from numpy import array\n",
    " \n",
    "# created input/output patterns from a sequence\n",
    "def supervised_for_lead_time(series, n_lag, lead_time):\n",
    "    data = list()\n",
    "    # enumerate observations and create input/output patterns\n",
    "    for i in range(n_lag, len(series)):\n",
    "        end_ix = i + (lead_time - 1)\n",
    "        # check if can create a pattern\n",
    "        if end_ix >= len(series):\n",
    "            break\n",
    "        # retrieve input and output\n",
    "        start_ix = i - n_lag\n",
    "        row = series[start_ix:i] + [series[end_ix]]\n",
    "        data.append(row)\n",
    "    return array(data)\n",
    " \n",
    "# define test dataset\n",
    "data = [x for x in range(20)]\n",
    "# convert to supervised format\n",
    "result = supervised_for_lead_time(data, 2, 6)\n",
    "# display result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create supervised learning data for each lead time for this target\n",
    "def target_to_supervised(chunks, rows, hours, col_ix, n_lag):\n",
    "    train_lead_times = list()\n",
    "    # get series\n",
    "    series = variable_to_series(rows, col_ix)\n",
    "    if not has_data(series):\n",
    "        return None, [nan for _ in range(n_lag)]\n",
    "    # impute\n",
    "    imputed = impute_missing(chunks, rows, hours, series, col_ix)\n",
    "    # prepare test sample for chunk-variable\n",
    "    test_sample = array(imputed[-n_lag:])\n",
    "    # enumerate lead times\n",
    "    lead_times = get_lead_times()\n",
    "    for lead_time in lead_times:\n",
    "        # make input/output data from series\n",
    "        train_samples = supervised_for_lead_time(imputed, n_lag, lead_time)\n",
    "        train_lead_times.append(train_samples)\n",
    "    return train_lead_times, test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training [var][lead time][sample] and test [chunk][var][sample]\n",
    "def data_prep(chunks, n_lag, n_vars=39):\n",
    "    lead_times = get_lead_times()\n",
    "    train_data = [[list() for _ in range(len(lead_times))] for _ in range(n_vars)]\n",
    "    test_data = [[list() for _ in range(n_vars)] for _ in range(len(chunks))]\n",
    "    # enumerate targets for chunk\n",
    "    for var in range(n_vars):\n",
    "        # convert target number into column number\n",
    "        col_ix = 3 + var\n",
    "        # enumerate chunks to forecast\n",
    "        for c_id in range(len(chunks)):\n",
    "            rows = chunks[c_id]\n",
    "            # prepare sequence of hours for the chunk\n",
    "            hours = variable_to_series(rows, 2)\n",
    "            # interpolate hours\n",
    "            interpolate_hours(hours)\n",
    "            # check for no data\n",
    "            if not has_data(rows[:, col_ix]):\n",
    "                continue\n",
    "            # convert series into training data for each lead time\n",
    "            train, test_sample = target_to_supervised(chunks, rows, hours, col_ix, n_lag)\n",
    "            # store test sample for this var-chunk\n",
    "            test_data[c_id][var] = test_sample\n",
    "            if train is not None:\n",
    "                # store samples per lead time\n",
    "                for lead_time in range(len(lead_times)):\n",
    "                    # add all rows to the existing list of rows\n",
    "                    train_data[var][lead_time].extend(train[lead_time])\n",
    "        # convert all rows for each var-lead time to a numpy array\n",
    "        for lead_time in range(len(lead_times)):\n",
    "            train_data[var][lead_time] = array(train_data[var][lead_time])\n",
    "    return array(train_data), array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_rows = array([row for rows in train for row in rows])\n",
    "#test_rows = to_forecasts(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by chunks\n",
    "train_chunks = to_chunks(train_rows)\n",
    "test_chunks = to_chunks(test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-99568af3a929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert training data into supervised learning data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_lag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## save train and test sets to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-6d429f340f26>\u001b[0m in \u001b[0;36mdata_prep\u001b[0;34m(chunks, n_lag, n_vars)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# enumerate chunks to forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m# prepare sequence of hours for the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mhours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_to_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# convert training data into supervised learning data\n",
    "n_lag = 12\n",
    "train_data, test_data = data_prep(train_chunks, n_lag)\n",
    "print(train_data.shape, test_data.shape)\n",
    "## save train and test sets to file\n",
    "#save('AirQualityPrediction/supervised_train.npy', train_data)\n",
    "#save('AirQualityPrediction/supervised_test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- https://machinelearningmastery.com/how-to-develop-machine-learning-models-for-multivariate-multi-step-air-pollution-time-series-forecasting/\n",
    "- [Download dataset](https://www.kaggle.com/c/dsg-hackathon/data)\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
