{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hnswlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3172e79b0ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhnswlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hnswlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import hnswlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.bpr import BayesianPersonalizedRanking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Inner Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix factorization are potent techniques in solving the collaborative filtering problem. It mainly involves building up the user-item interaction matrix, then decomposing it into a user latent factor (a.k.a embedding) and item latent factor each with some user specified dimension (a hyperparameter that we get to tweak).\n",
    "\n",
    "<img src=\"img/matrix_factorization.png\" width=\"60%\" height=\"60%\">\n",
    "\n",
    "To generate the items recommended for each user, we would perform a dot product between the two matrices and retrieve the top-k items that have the highest \"scores\". This process, however, can often times becomes a large bottleneck for these type of algorithms when the number of users and items becomes fairly large. As exhaustive computation of the dot product is extremely expensive. This document's focus is to demonstrate a order preserving transformation that converts the maximum inner product into a nearest neighborhood search problem to significantly speed up the process for generating the top-k recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Preserving Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first describe the notation we'll be using. Lower case is for scalars, $x$, bold lower case for vectors, $\\mathbf{x}$, and bold upper case for matrices, $\\mathbf{X}$.\n",
    "\n",
    "Given a vector, $\\mathbf{x}$. The norm is denoted by $\\Vert \\mathbf{x} \\Vert = \\sqrt{\\sum^d_{i=1} x_i^2}$. The inner product is represented as $\\mathbf{x} \\cdot \\mathbf{y}$. Last but not least, $(a, \\mathbf{x}^T)^T$ is for denoting a concatenation of a scalar $a$ with a vector $\\mathbf{x}$.\n",
    "\n",
    "On one hand, we have a matrix of $n$ vectors $\\mathbf{Y} = [\\mathbf{y}_1, \\mathbf{y}_2, ..., \\mathbf{y}_n]$, such that $\\mathbf{y}_i \\in \\mathbb{R}^d$. Where $d$ is the number of dimensions we set for the latent factor. Whereas, our query vector $\\mathbf{x} \\in \\mathbb{R}^d$.\n",
    "\n",
    "Our objective is to retrieve an index according to the maximum inner product.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(\\mathbf{Y}, \\mathbf{x}) = \\underset{i}{\\text{argmax}} \\space \\mathbf{x} \\cdot \\mathbf{y}_i\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The idea behind speeding up the workload for maximum inner product operations is to transform the problem into a distance minimization problem or nearest neighborhood search.\n",
    "\n",
    "\\begin{align}\n",
    "f(\\mathbf{Y}, \\mathbf{x}) = \\underset{i}{\\text{argmin}} \\space {\\Vert \\mathbf{x} - \\mathbf{y}_i \\Vert}^2\n",
    "\\end{align}\n",
    "\n",
    "Once we transform the problem into a euclidean distance problem, there are plethora of algorithms/packages available for doing fast similarity search. To do so, we are going to apply a transformation function on our matrix, $\\mathbf{Y}$and our query vector, $\\mathbf{x}$. Note that the idea here is only to perform transformation on top of the existing $\\mathbf{x}$ and $\\mathbf{y}$, not to design a whole new algorithm in itself to learn embeddings/latent factors that directly uses distance minimization to generate the prediction, as this prevents us from using the existing matrix factorization algorithms.\n",
    "\n",
    "The order transformation is to add an additional dimension to each of the latent factors:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{y}_i^* &= \\big(\\sqrt{\\phi^2 - {\\Vert \\mathbf{y_i} \\Vert}^2 }, \\mathbf{y_i}^T\\big)^T, \\text{where } \\phi = \\underset{i}{\\text{max}} \\Vert \\mathbf{y}_i \\Vert \\\\\n",
    "\\mathbf{x}^* &= (0, \\mathbf{x}^T)^T\n",
    "\\end{align}\n",
    "\n",
    "As\n",
    "\n",
    "\\begin{align}\n",
    "{\\Vert \\mathbf{x}^* \\Vert}^2 &= {\\Vert \\mathbf{x} \\Vert}^2 \\\\\n",
    "{\\Vert \\mathbf{y}_i^* \\Vert}^2 &= \\phi^2 - {\\Vert \\mathbf{y}_i \\Vert}^2 + {\\Vert \\mathbf{y}_i \\Vert}^2 = \\phi^2 \\\\\n",
    "\\mathbf{x}^* \\cdot \\mathbf{y}^*_i &= \\sqrt{\\phi^2 - {\\Vert \\mathbf{y}_i \\Vert}^2 } \\cdot 0 + \\mathbf{x} \\cdot \\mathbf{y}_i = \\mathbf{x} \\cdot \\mathbf{y}_i\n",
    "\\end{align}\n",
    "\n",
    "To link the maximum inner product to the distance minimization problem, we would then have:\n",
    "\n",
    "\\begin{align}\n",
    "{\\Vert \\mathbf{x}^* - \\mathbf{y}_i^* \\Vert}^2 = {\\Vert \\mathbf{x}^* \\Vert}^2 + {\\Vert \\mathbf{y}_i^* \\Vert}^2 - 2 \\cdot \\mathbf{x}^* \\cdot \\mathbf{y}^*_i = {\\Vert \\mathbf{x} \\Vert}^2 + \\phi^2 - 2 \\cdot \\mathbf{x} \\cdot \\mathbf{y}_i\n",
    "\\end{align}\n",
    "\n",
    "Since both $\\mathbf{x}$ and $\\phi$ are independent of the term $i$, that concludes our order preserving transformation.\n",
    "\n",
    "Upon building the transformation, our original matrices would have 1 extra dimension. Then the next step is to pick our favorite nearest neighborhood algorithm and use it to generate the predictions. Popular options at the time of writing this includes, [faiss](https://github.com/facebookresearch/faiss), [nmslib](https://github.com/nmslib/nmslib), or [hnswlib](https://github.com/nmslib/hnswlib). The [ann-benchmarks](https://github.com/erikbern/ann-benchmarks) also lists down the comparison between different open-source nearest neighborhood search algorithms/packages.\n",
    "\n",
    "Let's now take a look at these concepts in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the movielens data to illustrate to concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: \n",
      " (100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = 'ml-100k'\n",
    "file_path = os.path.join(file_dir, 'u.data')\n",
    "if not os.path.isdir(file_dir):\n",
    "    call(['curl', '-O', 'http://files.grouplens.org/datasets/movielens/' + file_dir + '.zip'])\n",
    "    call(['unzip', file_dir + '.zip'])\n",
    "\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(file_path, sep='\\t', names=names)\n",
    "print('data dimension: \\n', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_col = 'user_id'\n",
    "items_col = 'item_id'\n",
    "value_col = 'rating'\n",
    "time_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (users_col, items_col):\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the train/test split, the process is to split each user's behavior based on chronological order. e.g. If an user interacted with 10 items, and we specify a test set of size, 0.2. Then the first 8 items that the user first interacted with will fall in the training set, and the last 2 items will belong to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_user_time_split(df: pd.DataFrame, test_size: float=0.2):\n",
    "    train_size = 1 - test_size\n",
    "\n",
    "    df_train_user = []\n",
    "    df_test_user = []\n",
    "    df_grouped = df.sort_values(time_col).groupby(users_col)\n",
    "    for name, df_group in df_grouped:\n",
    "        n_train = int(df_group.shape[0] * train_size)\n",
    "        df_group_train = df_group.iloc[:n_train]\n",
    "        df_group_test = df_group.iloc[n_train:]\n",
    "        df_train_user.append(df_group_train)\n",
    "        df_test_user.append(df_group_test)\n",
    "\n",
    "    df_train = pd.concat(df_train_user, ignore_index=True)\n",
    "    df_test = pd.concat(df_test_user, ignore_index=True)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  79619\n",
      "test size:  20381\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "df_train, df_test = train_test_user_time_split(df, test_size)\n",
    "\n",
    "print('train size: ', df_train.shape[0])\n",
    "print('test size: ', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we'll be using is Bayesian Personalized Ranking from the [implicit](https://github.com/benfred/implicit) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1682x943 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 79619 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = df[users_col].cat.categories.shape[0]\n",
    "n_items = df[items_col].cat.categories.shape[0]\n",
    "\n",
    "# implicit library expects items to be rows\n",
    "# and users to be columns of the sparse matrix\n",
    "rows = df_train[items_col].cat.codes.values\n",
    "cols = df_train[users_col].cat.codes.values\n",
    "values = df_train[value_col].astype(np.float32)\n",
    "item_user = csr_matrix((values, (rows, cols)), shape=(n_items, n_users))\n",
    "item_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee67ea977e554f999a756d4c669d3d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# we won't be doing any hyperparameter tuning\n",
    "# as training the \"best\" model is not the main purpose here\n",
    "bpr = BayesianPersonalizedRanking()\n",
    "bpr.fit(item_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model object also provides a `.recommend` method that generates the recommendation for a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(174, 3.0052617),\n",
       " (180, 2.8591871),\n",
       " (143, 2.6832802),\n",
       " (49, 2.6188507),\n",
       " (213, 2.6169426)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 0\n",
    "topn = 5\n",
    "\n",
    "user_item = item_user.T.tocsr()\n",
    "recommendations = bpr.recommend(user_id, user_item, topn, filter_already_liked_items=False)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate the recommendations ourselves. We'll first confirm that the `recommend` function that we've implemented matches the one provided by the library, also implement a `recommend_all` function that generates the recommendation for all the user, this will be used to compare against the nearest neighborhood search on the order transformed matrix later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(query_factors, index_factors, query_id, topn=5):\n",
    "    output = query_factors[query_id].dot(index_factors.T)\n",
    "    argpartition_indices = np.argpartition(output, -topn)[-topn:]\n",
    "    sort_indices = np.argsort(output[argpartition_indices])[::-1]\n",
    "    labels = argpartition_indices[sort_indices]\n",
    "    distances = output[labels]\n",
    "    return labels, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different model/library have different ways of extracting the item and user factors/embeddings, we assign it to `index_factors` and `query_factors` to make all downstream code agnostic of libraries' implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174 180 143  49 213]\n",
      "[3.0052617 2.8591871 2.6832802 2.6188507 2.6169426]\n"
     ]
    }
   ],
   "source": [
    "index_factors = bpr.item_factors\n",
    "query_factors = bpr.user_factors\n",
    "labels, distances = recommend(query_factors, index_factors, user_id, topn)\n",
    "\n",
    "print(labels)\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_all(query_factors, index_factors, topn=5):\n",
    "    output = query_factors.dot(index_factors.T)\n",
    "    argpartition_indices = np.argpartition(output, -topn)[:, -topn:]\n",
    "\n",
    "    x_indices = np.repeat(np.arange(output.shape[0]), topn)\n",
    "    y_indices = argpartition_indices.flatten()\n",
    "    top_value = output[x_indices, y_indices].reshape(output.shape[0], topn)\n",
    "    top_indices = np.argsort(top_value)[:, ::-1]\n",
    "\n",
    "    y_indices = top_indices.flatten()\n",
    "    top_indices = argpartition_indices[x_indices, y_indices]\n",
    "    labels = top_indices.reshape(-1, topn)\n",
    "    distances = output[x_indices, top_indices].reshape(-1, topn)\n",
    "    return labels, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[174 180 143  49 213]\n",
      " [285  13 274 125 284]\n",
      " [299 330 332 331 287]\n",
      " ...\n",
      " [256 287   6   0 221]\n",
      " [312 299 315 271 314]\n",
      " [ 68  55 203 469 567]]\n",
      "[[3.0052621 2.8591871 2.6832805 2.6188507 2.6169431]\n",
      " [4.053235  3.6379702 3.6113174 3.5244005 3.5000963]\n",
      " [4.46495   4.380792  4.2894416 4.280343  4.2222657]\n",
      " ...\n",
      " [2.9497485 2.9439096 2.942726  2.8972204 2.8738377]\n",
      " [3.186943  3.1394417 3.1009166 2.9625754 2.9234204]\n",
      " [3.7362995 3.5745556 3.5423145 3.4201126 3.3898365]]\n"
     ]
    }
   ],
   "source": [
    "labels, distances = recommend_all(query_factors, index_factors)\n",
    "print(labels)\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement our order preserving transformation, we first apply the transformation on our index factors. Recall that the formula is: Let $\\phi = \\underset{i}{\\text{max}} \\Vert \\mathbf{y}_i \\Vert$. $\\mathbf{y}_i^* = g(\\mathbf{y}_i) = \\big(\\sqrt{\\phi^2 - {\\Vert \\mathbf{y_i} \\Vert}^2 }, \\mathbf{y_i}^T\\big)^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_inner_product(factors):\n",
    "    normed_factors = np.linalg.norm(factors, axis=1)\n",
    "    max_norm = normed_factors.max()\n",
    "    \n",
    "    extra_dim = np.sqrt(max_norm ** 2 - normed_factors ** 2).reshape(-1, 1)\n",
    "    augmented_factors = np.append(factors, extra_dim, axis=1)\n",
    "    return max_norm, augmented_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre shape:  (1682, 101)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1682, 102)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('pre shape: ', index_factors.shape)\n",
    "max_norm, augmented_index_factors = augment_inner_product(index_factors)\n",
    "augmented_index_factors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to use our favorite nearest neighborhood search algorithm/library to conduct the search. We'll be leveraging [hnswlib](https://github.com/nmslib/hnswlib) in this example, explaining the details behind the this nearest neighborhood search algorithm is beyond the scope of this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hnsw(factors, space, ef_construction, M):\n",
    "    # Declaring index\n",
    "    max_elements, dim = factors.shape\n",
    "    hnsw = hnswlib.Index(space, dim) # possible options for space are l2, cosine or ip\n",
    "\n",
    "    # Initing index - the maximum number of elements should be known beforehand\n",
    "    hnsw.init_index(max_elements, M, ef_construction)\n",
    "\n",
    "    # Element insertion (can be called several times)\n",
    "    hnsw.add_items(factors)\n",
    "    return hnsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09450387954711914"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the library directly supports inner product,\n",
    "# this might not be the case for all the nearest neighborhood search library\n",
    "space = 'ip'\n",
    "ef_construction = 400\n",
    "M = 24\n",
    "\n",
    "start = time.time()\n",
    "hnsw = build_hnsw(augmented_index_factors, space, ef_construction, M)\n",
    "build_time = time.time() - start\n",
    "build_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the the prediction, we first transform the incoming \"queries\". $\\mathbf{x}^* = h(\\mathbf{x}) = (0, \\mathbf{x}^T)^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 102)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_zero = np.zeros((query_factors.shape[0], 1))\n",
    "augmented_query_factors = np.append(query_factors, extra_zero, axis=1)\n",
    "augmented_query_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[174 180 143  49 213]\n",
      " [285  13 274 125 284]\n",
      " [299 330 332 331 287]\n",
      " ...\n",
      " [256 287   6   0 221]\n",
      " [312 299 315 271 314]\n",
      " [ 68  55 203 469 567]]\n",
      "[[3.0052621 2.859187  2.6832802 2.6188505 2.6169431]\n",
      " [4.053235  3.63797   3.6113174 3.5244007 3.5000958]\n",
      " [4.4649506 4.380792  4.2894416 4.2803426 4.2222657]\n",
      " ...\n",
      " [2.9497485 2.9439096 2.942726  2.8972206 2.8738375]\n",
      " [3.1869428 3.139442  3.1009169 2.9625754 2.9234204]\n",
      " [3.7362995 3.5745554 3.5423145 3.4201126 3.3898368]]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "# Controlling the recall by setting ef, should always be > k\n",
    "hnsw.set_ef(70)\n",
    "\n",
    "# retrieve the top-n search neighbors\n",
    "label, distance = hnsw.knn_query(augmented_query_factors, k=k)\n",
    "print(label)\n",
    "\n",
    "# the distance returned by hnsw is 1 - inner product, hence\n",
    "# we convert it back to just inner product\n",
    "print(1 - distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can time the original recommend method using maximum inner product versus the new method of using the order preserving transformed matrices with nearest neighborhood search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.4 ms ± 280 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "recommend_all(query_factors, index_factors, topn=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ms ± 537 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "extra_zero = np.zeros((query_factors.shape[0], 1))\n",
    "augmented_query_factors = np.append(query_factors, extra_zero, axis=1)\n",
    "hnsw.knn_query(query_factors, k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the timing is highly dependent on the dataset. We'll observe a much larger speedup if the number of items/labels in the output/index factor is larger. In the movielens dataset, we only had to rank the top items for each user among 1.6K items, in a much larger dataset, the number of items could easily go up to 100K or even million, that's when we'll see the real potential of this method.\n",
    "\n",
    "Another thing worth checking is the quality of the prediction using the new method. Here we're using hnswlib library to generate the nearest neighborhood items, as hnswlib is technically an approximate nearest neighborhood algorithm. We can measure how much overlap the approximate top recommendations are to the original top recommendations to make sure we are using the right parameters for the nearest neighborhood search algorithm. Notation-wise:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{overlap@k} = \\frac{|L_{rec} \\cap L_{opt}|}{k}\n",
    "\\end{align}\n",
    "\n",
    "Where $L_{rec}$ and $L_{opt}$ are the lists of top k approximate recommendations and top k optimal/original recommendations respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, distances = recommend_all(query_factors, index_factors, topn=k)\n",
    "hnsw_labels, hnsw_distances = hnsw.knn_query(query_factors, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_label_precision(optimal_labels, reco_labels):\n",
    "    n_labels = len(optimal_labels)\n",
    "    label_precision = 0.0\n",
    "    for optimal_label, reco_label in zip(optimal_labels, reco_labels):\n",
    "        topn = len(reco_label)\n",
    "        precision = len(set(optimal_label) & set(reco_label)) / topn\n",
    "        label_precision += (precision / n_labels)\n",
    "\n",
    "    return round(label_precision, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as expected, the precision between itself should be 1\n",
    "label_precision = compute_label_precision(labels, labels)\n",
    "label_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.909"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure the approximate neighborhood search is of good quality\n",
    "label_precision = compute_label_precision(labels, hnsw_labels)\n",
    "label_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Github: Hnswlib - fast approximate nearest neighbor search](https://github.com/nmslib/hnswlib)\n",
    "- [Blog: Approximate Nearest Neighbours for Recommender Systems](http://www.benfrederickson.com/approximate-nearest-neighbours-for-recommender-systems/)\n",
    "- [Paper: Y. Bachrach, Y. Finkelstein, R. Gilad-Bachrach, L. Katzir, N. Koenigstein, N. Nice, U. Paquet - Speeding Up the Xbox Recommender System Using a Euclidean Transformation for Inner-Product Spaces (2016)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/XboxInnerProduct.pdf)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "199.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
